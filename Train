import seaborn as sns
import pandas as pd

# Get folds only
fold_cols = [col for col in cv_results.columns if 'split' in col and 'test_score' in col]
folds_df = cv_results[fold_cols].copy()
folds_df = -folds_df  # Convert neg_MSE to positive MSE
folds_df.columns = [col.replace('_test_score', '') for col in folds_df.columns]
folds_df.index = [f'Model {i+1}' for i in range(len(folds_df))]

plt.figure(figsize=(10, 6))
sns.heatmap(folds_df, annot=True, fmt=".5f", cmap="YlGnBu", cbar_kws={'label': 'MSE'})
plt.title("MSE per Fold for Each Model (Cross-Validation)")
plt.xlabel("Fold")
plt.ylabel("Model")
plt.tight_layout()
plt.show()




import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.errorbar(
    range(len(sorted_results)),
    -sorted_results['mean_test_score'],  # Mean MSE
    yerr=sorted_results['std_test_score'],  # STD MSE
    fmt='o',
    capsize=5,
    ecolor='gray',
    label='Mean MSE Â± STD (CV)'
)

plt.xticks(
    range(len(sorted_results)),
    [f"Model {i+1}" for i in range(len(sorted_results))],
    rotation=45
)

plt.title('Cross-validation MSE by Hyperparameter Combination')
plt.ylabel('Mean Squared Error')
plt.xlabel('Hyperparameter Combinations')
plt.grid(True)
plt.tight_layout()
plt.legend()
plt.show()





best_row = sorted_results.iloc[0]
print("Best Model Parameters:")
print(best_row['params'])
print(f"Mean MSE: {-best_row['mean_test_score']:.5f}")
print(f"STD: {best_row['std_test_score']:.5f}")




import matplotlib.pyplot as plt

# Sort results by mean_test_score (descending)
sorted_results = cv_results.sort_values('mean_test_score', ascending=False).reset_index(drop=True)

# Create plot
plt.figure(figsize=(10, 6))
plt.errorbar(
    range(len(sorted_results)),
    -sorted_results['mean_test_score'],  # negate because it's neg MSE
    yerr=sorted_results['std_test_score'],
    fmt='o',
    ecolor='gray',
    capsize=5,
    label='Cross-validation MSE'
)

# Add labels
plt.title('Cross-Validation Results for GPR Hyperparameter Search')
plt.xlabel('Hyperparameter Combination (sorted by performance)')
plt.ylabel('Mean Squared Error (lower is better)')
plt.xticks(range(len(sorted_results)), labels=[f'Model {i+1}' for i in range(len(sorted_results))], rotation=45)
plt.grid(True)
plt.tight_layout()
plt.legend()
plt.show()






from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Lambda
import tensorflow as tf

# Define the input shape for the features (excluding oil labels)
input_shape = X_oil1_train.shape[1]  # Number of features

# Input layer for the features (excluding oil label)
feature_input = Input(shape=(input_shape,))

# Input for the oil label (this is a single value, so the shape is (1,))
oil_label_input = Input(shape=(1,))

# Shared layers for feature extraction from the features
shared_layer = Dense(128, activation='relu')(feature_input)
shared_layer = Dense(64, activation='relu')(shared_layer)

# Task-specific outputs based on the oil label
output1 = Dense(1, activation='linear', name='oil_1_output')(shared_layer)
output2 = Dense(1, activation='linear', name='oil_2_output')(shared_layer)
output3 = Dense(1, activation='linear', name='oil_3_output')(shared_layer)

# Custom function to choose the correct output based on the oil label
def choose_output(inputs):
    oil_label, output1, output2, output3 = inputs
    return tf.where(tf.equal(oil_label, 0), output1, 
           tf.where(tf.equal(oil_label, 1), output2, output3))

# Apply the oil label to select the correct output
chosen_output = Lambda(choose_output)([oil_label_input, output1, output2, output3])

# Define the model
model = Model(inputs=[feature_input, oil_label_input], outputs=chosen_output)

# Compile the model
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Summary of the model
model.summary()



# Combine training data (features and labels)
X_comb_train = np.vstack((X_oil1_train, X_oil2_train, X_oil3_train))
y_comb_train = np.hstack((y_oil1_train, y_oil2_train, y_oil3_train))

# Create oil labels (0 for oil1, 1 for oil2, 2 for oil3)
oil_labels_train = np.array([0] * len(X_oil1_train) + [1] * len(X_oil2_train) + [2] * len(X_oil3_train))

# Train the model
history = model.fit(
    [X_comb_train, oil_labels_train],  # Features and oil labels as input
    y_comb_train,  # Combined labels
    epochs=50,
    batch_size=32,
    validation_data=([X_comb_val, oil_labels_val], y_comb_val)  # Combined validation data
)


